\documentclass[11pt,a4paper,titlepage]{report}


% Document settings

\title{OSP Project Specification \\ Team $\langle$sql injection$\rangle$}

\author{
  Neil Ang\\
  \texttt{s3251533}
  \and
  ``Alfred" Yang Yuan\\
  \texttt{s3363619}
  \and
  Val Lyashov\\
  \texttt{s3366222}
}

\date{Semester 2, 2013}


% Change section numbering
%\renewcommand\thesection{\Roman{section}}
%\renewcommand\thesubsection{\Alph{subsection}}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}


% Enable smart quotes
\usepackage [english]{babel}
\usepackage [autostyle]{csquotes}
\MakeOuterQuote{"}


% Set watermark while in development
%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT}
%\SetWatermarkScale{5}
%\SetWatermarkColor[gray]{0.95}


% Alias pi name
\usepackage{xspace}
\newcommand{\rpi}{\textit{Raspberry Pi\textsuperscript{\textregistered}}}
\newcommand{\rpis}{\textit{Raspberry Pi\textsuperscript{\textregistered}s}}

% Side by side graphics
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% Switch to biblatex
\usepackage{biblatex}
\bibliography{computer-vision}
\bibliography{audio}
\bibliography{servo}

% Add the bib to the toc
\DefineBibliographyStrings{english}{
  bibliography = {Bibliography},
}

%For process listing
\usepackage{dirtree}
%\usepackage{qtree}

\usepackage{multicol}

% Stop tables being repositioned
\usepackage{float}
\restylefloat{table}

% Better table height
\usepackage{tabu}

% The appendix
\usepackage{appendix}

% Code highlighting
\usepackage{listings}
\lstset{basicstyle=\ttfamily}

% For marking what's left to do
\usepackage{color}


\begin{document}


\maketitle

\pagebreak
\tableofcontents
\thispagestyle{empty}
\pagebreak

\section{Introduction}

Our project will attempt to modernise the phonograph by using the \rpi\xspace for subject tracking, digital recording and audio processing. A directional microphone will be installed on a custom mount that can be programmatically moved in an X and Y direction. A connected camera will then be used to detect the subject (e.g. through face detection) and adjust the position of the microphone accordingly. A secondary goal of the project is to then process the audio through an Internet based voice-to-text service, and produce saved audio recordings with completed transcripts.

The final solution will be a relatively cheap, portable and smart recording device suitable for use in a lecture theatre or classroom. It would be ideal for assisting students in note taking, or for lecturers teaching in learning spaces that haven't been outfitted with full featured recording systems (such as the \textit{Lectopia}\footnote{http://www.rmit.edu.au/teaching/technology/lecturecapture} or \textit{Echo360}\footnote{http://www.rmit.edu.au/teaching/technology/echo360} systems used at \textit{RMIT}).


\section{System Overview}

This is an ambitious project and involves a lot of complex processing and interaction with hardware. To distribute the CPU workload and modularise the solution, the functionality will be spread over two \rpis. This will also have the added benefit of making it easier to work on as a group, because the components can be worked on independently of each other.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{graphs/rpi_1.pdf}
\caption{Connected hardware for computer vision component of project. It includes a power supply, motion sensor, RPi camera board, servo controller and two servos.}
\label{fig:cvhardware}
\end{figure}


The first \rpi\xspace will be responsible for subject tracking using computer vision. It will detect the subject via an attached camera and communicate directly with a servo controller to move the microphone mount. In an effort to conserve power, this \rpi\xspace will also have a motion sensor connected to one of its General Purpose Input/Output (GPIO) ports. When no motion is detected, it will power down the connected peripherals. Figure \ref{fig:cvhardware} illustrates the connected components for this device.


\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{graphs/rpi_2.pdf}
\caption{Connected hardware for audio recording component of project. It includes a power supply, sound card, shotgun microphone and wireless card.}
\label{fig:audiohardware}
\end{figure}

The second \rpi\xspace will be responsible for the audio recording and processing. It will have a shotgun (or directional) microphone connected to it via an USB sound card.  As audio is recorded it perform voice-to-text processing through a web service. A USB wireless card will be attached to support connecting to the Internet. Figure \ref{fig:audiohardware} illustrates the connected components for this device.

Both \rpis\xspace will also be networked together via their ethernet ports for inter-device communication. For a detailed summary of all involved hardware and its purpose in the project, see Table \ref{table:hardwaretable}. 


\begin{center}
\begin{table}
{\tabulinesep=1.8mm
\begin{tabu}{ lcp{7cm} }

    \textbf{Hardware} & \textbf{Qty} & \textbf{Purpose} \\ \hline
    
    \rpi & 2 & Due to the inherent complexity of audio and video processing, the solution workload will be split across two \rpis. The first will handle the computer vision and controlling the servos. The second is for processing audio and data storage.\\ 

    \textit{Camera} & 1 & Either a RPi Camera board or USB web cam will be used for subject tracking through computer vision. \\ 
    
   \textit{Servos} & 2 & Two servos will be used to control the microphone mount. One servo will manoeuvre the mount on an X axis, while the other is used for the Y axis. \\ 
        
    \textit{USB servo controller} & 1 & This will be used to improve the movement accuracy of the servos \\ 
    
    \textit{USB sound card} & 1 & The \rpi\xspace has no in-built audio input jack, so an external sound card will be used to facilitate connecting the microphone. \\ 
    
    \textit{Shotgun microphone} & 1 & This microphone will give us targeted audio for recording voice and minimising background noise. \\ 
    
    \textit{Motion sensor} & 1 & To conserve power before and after a recording session, a motion sensor will be used to detect the presence of a subject in the room. The system will enter a "standby mode" if no movement is detected.\\ 

    \textit{Power supply} & 2 & To take advantage of the lightweight nature of the \rpi\xspace and components, an external battery pack would be an ideal supply to keep the system portable.\\ 


    \textit{Wireless card} & 1 & The voice-to-text processing will be performed remotely, so an unobtrusive internet connection will be required.\\ \hline
    
\end{tabu} }
\caption{Summary of hardware}
\label{table:hardwaretable}
\end{table}

\end{center}

\section{Design Considerations}

Early experiments have indicated that face detection and audio processing will be very CPU intensive. To ensure the system runs smoothly, we will need to optimise the system as much as possible. For example, although using Python would be acceptable for prototyping scripts, the final implementation of the software will be re-written in C/C++ for for optimal performance.

As this is a fairly complex project, we will also need to find ways to modularise the hardware and software components. This is so they can be developed in parallel by different group members, as well as making it easier to redesign components of the system if any problems arise.

Finally, a physical design consideration will be to build a sturdy, easy to assemble, portable system. Ideally we will try to construct a batter powered low consuming system. Powering the solution by battery will not difficult, but we will need to intelligently invent ways to reduce resource usage to increase battery performance. This will include powering hardware on and off when not in use and keeping CPU usage to a minimum on both devices. Although we will endeavour to design the project to be power conservative, we will only explore  battery power if we have time remaining at the end of the project. 


\subsection{Goals and Objectives}

This project aims to provide an easy way to audio record and annotate lectures, talks and other presentations. As students, it is something we would like to use ourselves. However we are also attempting to meet all learning objectives of the assignment as well.

\begin{description}
   
  \item[Personal goals] \hfill \\
      Design a solution that is to be relatively portable, requires minimal setup and start-up time. 
      
  \item[Learning objective 1] \hfill \\
%\textit{Design, develop, test, and debug a complex system-level program on a resource constrained device using appropriate development environments, debuggers, unit testing tools, and version control tools.}
%\\ \\
The \rpi\xspace is a resource constrained device, so for this objective will ensure that our system runs efficiently with the hardware available. We will achieve this by running performance tests for all software components and introducing clever ways (e.g. using the motion sensor) to reduce CPU and conserve power. 

All source code and project documentation for this project will be version controlled through \textit{git}, and hosted on a private\footnote{Access to this repository is available upon request.} \textit{GitHub} repository along with our project wiki and development logs.

  \item[Learning objective 2] \hfill \\
%\textit{Assess how computing resources are used by the application software and managed by the system software. Analyse the inherent trade-offs between hardware constraints and system software.}
%\\ \\
The system will be built on a bare-bones linux distribution and designed so that each sub-components of the main software application will be responsible for interfacing with only one hardware feature (e.g. the \textit{comms} code will be the only process/thread that can access the ethernet port, and the \textit{face-detect} process/thread will be the only code to access the camera). Building the solution in this manner, with no other programs competing for resources is how we will effectively manage the hardware.

  \item[Learning objective 3] \hfill \\
  %\textit{Construct appropriate diagrams and textual descriptions to communicate a system level program design and how it integrates one or more of the following key OS concepts: a. kernel and hardware interaction; b. processes and interprocess communication; c. concurrency and synchronisation; d. pre-emptive and non-preemptive scheduling; e. memory hierarchy, management, and cost-performance trade-offs; f. file system design and implementation; and/or g. security and privacy.}
%// // 
We will cover this in detail in the final portfolio through diagrams and descriptions of the system design.

  \item[Learning objective 4] \hfill \\
%\textit{Describe the full range of considerations of effective and efficient teamwork.}
As a team we have assigned primary roles which make best use of our individual skills. However, to increase each group members personal learning in areas they are not already accomplished in, we've allowed for some overlap in the roles. For example, Val who has expertise in Unix/Hardware, will also attempt to prototype some of the hardware interfaces in Python. Neil, who doesn't have much hardware or C/C++ experience, will then port the Python scripts to C/C++. The primary responsibilities for the roles will still lie with designated group member, but everyone will have the opportunity to try something they haven't worked on before.

\end{description}




\subsection{Assumptions and Dependencies}

Due to time constraints, we will be dependant on a 3rd party framework for subject detection. We've already done some preliminary research and experimented with OpenCV\footnote{http://opencv.org/} for facial recognition.

When recording an audio session through our product, we have also made the assumption that the system will be able to be placed front-on to the subject, and the recording environment will be reasonably lit.


\subsection{General Constraints}

A major constraint of this project it the processing power of the \rpi. Preliminary investigations suggested that depth sensing would be a more accurate subject tracking technique, but the \rpi\xspace would not have the processing power required for skeletal mapping. We have opted to use simpler face detection instead, but its effectiveness will be limited by the light in the room, the direction the subject is facing and any obstruction of the facial features.

As we are building moving parts into the project, we will also be constrained by the total weight of the hardware. There is a physical limit to the servos torque and we have to ensure we don't exceed the weight limit in our mount design.

Finally, the biggest constraint of the project is time. The project is very ambitious, with a lot of individual things that could not turn out as planned. Adapting to these issues will become increasingly limiting as we approach the delivery date.


\subsection{Development Methodology}

The project will constructed over 3 main stages in isolated parts by all group members. 


\subsubsection{Stage 1}

The first stage will attempt to solve the hardest issues of face recognition and physical movement. We will also need to demo our cross-compiler and develop the project specification.

\begin{table}[H]
\begin{tabular}{|l|c|c|}
    \hline
    \textbf{Objective} & \textbf{Members} & \textbf{Week} \\ \hline
    
    Lab demo & All & 5 \\ \hline
    OpenCV tracking & Alfred, Neil & 4, 5, 6 \\ \hline
    Servo movement & Val & 4, 5, 6 \\ \hline
    Project Specification & Neil & 6 \\ \hline

\end{tabular}
\end{table}

\subsubsection{Stage 2}

Stage two will also encapsulate the mid-semester break. We will combine what was built in the first stage and start work on implementing audio features of the second \rpi.

\begin{center}
\begin{table}[H]
\begin{tabular}{|l|c|c|}
    \hline
    \textbf{Objective} & \textbf{Members} & \textbf{Week} \\ \hline
    
    Servo Mount & Val & 7 \\ \hline
    Audio recording & Val & 8 \\ \hline
    Pi device comms & Alfred & 7 \\ \hline
    Server complete & Alfred & 8 \\ \hline
    PIR monitor & Neil & 7 \\ \hline
    Integrated Face tracking /w Servo & Neil & 8 \\ \hline


\end{tabular}
\end{table}
\end{center}


\subsubsection{Stage 3}

Final stage will involve putting all the finished pieces together. We will also need to deliver our presentation and portfolio in this stage.


\begin{center}
\begin{table}[H]
\begin{tabular}{|l|c|c|}
    \hline
    \textbf{Objective} & \textbf{Members} & \textbf{Week} \\ \hline

    Data storage & Neil & 9 \\ \hline    
    Voice-to-text & Val & 9 \\ \hline    
    Client complete & Alfred & 9 \\ \hline    
    Demo & All & 10 \\ \hline    
    Portfolio & All & 12 \\ \hline    

\end{tabular}
\end{table}
\end{center}

\subsubsection{Stage 4}

In the event that the group finishes the project early we can optionally explore power improvements to the project. This would include benchmarking and tracking power usage with the hardware, re-designing all the hardware to powered by battery, and integrating an in-progress battery indicator into the project.



\section{Architecture}

The construction of the system will be complex due to the number things we need to achieve. These include a technical design with compatible hardware, a stripped back operating system, an efficient software layer, and a physical design that is portable.

\subsection{System Design}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{graphs/init_bb.pdf}
\caption{Wiring design for servo controller and PIR-sensor.}
\label{fig:initbb}
\end{figure}



The project hardware will consist of two \rpis\xspace working in parallel as a complete system. Communication between the two \rpi\xspace devices will be done through a central messaging system, enhancing modularity of project components.

The pan and tilt motion of the project will be provided by two servos connected to an USB \textit{Pololu Maestro} servo controller. The benefit of an external hardware controller is much greater accuracy and reduced latency of servo responses. Communication is achieved through the virtual serial port over the USB, utilising \textit{Pololu's} proprietary communications protocol\footnote{http://www.pololu.com/docs/0J40/5.c}. The external controller requires a 5V rail to power servo movements. Early experimentation showed the \rpis\xspace on-board 5V is unreliable for burst usage, causing the device to restart. Figure \ref{fig:initbb} for a high level illustrations of how the servo hardware is wired to the \rpi.


As the \rpi\xspace devices don't have built-in microphone input ports, sound recording will be enabled through an USB sound card. Initial tests show a requirement for this sound card to be physically connected away from the \rpi\xspace as the circuit design generates notable line noise.

Power will be delivered by a single powered USB hub that is also connecting the first \rpi\xspace to the USB camera and external servo controller. An additional 5V of power will be delivered by an external 4xAA battery pack for movement of the servos.

In order to reduce overall power consumption of the system, a passive infrared (PIR) proximity sensor will be utilised to detect motion in line-of-sight of the RPi camera board. 

\subsection{Data Design}

It is undecided if we will implement the program through threads or sub-processes. Either way we will need to devise a solution for inter-process communication. For inter-device communication we will implement a message queue protocol over TCP, utilising the \rpis\xspace native RJ45 connector.

One notable issue that is still to be addressed is the efficient storage of audio data from recording sessions. The group has already started researching fast encoding algorithms and formats to reduce data offloading requirements and increases the operational time of the end-device. Possible solutions explored to date include external hardware mp3 encoders as well as fast FLAC encoding software solutions.


\subsection{Program Design}

There will be a custom main program running on each \rpi. The one on the computer vision device will act like a \textit{server}, and the audio recording device will behave like a \textit{client}. These program will spawn and manage sub-processes or threads to be responsible for individual tasks. For simplicity they will just be referred to as "sub-processes" in the below descriptions. Figure \ref{fig:processes} is a high level summary of the components that make up each main program.

\begin{figure}
\begin{multicols}{2}
\dirtree{%
.1 server.
.3 pir-monitor.
.3 face-detect.
.3 servo-ctrl.
.3 comm.
}\columnbreak
\dirtree{%
.1 client.
.3 voice-ctrl.
.3 text-to-speech.
.3 comm.
}
\end{multicols}
\caption{A modularised representation of each programs sub-processes.}\label{fig:processes}
\end{figure}

\subsubsection{server and client}


The \textit{server} will have three state based modes, which will inform how its sub-processes behave. It's states will be "standby", "seeking" and "active". The "standby" mode will halt any unnecessary power usage, the "seeking" mode will inform the processes to seek out a target, and the "active" mode will be used for normal operation. 

The \textit{client} will also be state based, but only use "standby" and "active". Its state will be set and updated by the \textit{server} program.


\subsubsection{pir-monitor}

The \textit{pir-monitor} will be responsible for recording motion detection in the room. It will listen to a passive infrared sensor (or PIR-sensor) connected to the GPIO pins on the device. Whenever it detects movement in the room, the sub-process will pipe out the current timestamp to a shared memory location. The \textit{server} will periodically check the timestamp for recency, and use this information to assist in choosing the next system state.


\subsubsection{face-detect}

The \textit{face-detect} is responsible for controlling the connected camera hardware and looking for faces in captured images. It will continually request an image from the camera and process the image to determine where a face is located. The coordinates of a face will be communicated with the \textit{servo-ctrl} for updating its position.


\subsubsection{servo-ctrl}

The \textit{servo-ctrl} is responsible for orienting the microphone and camera in the right direction. It will receive instructions from the \textit{face-detect} sub-process and adjust its positioning to try and centre the camera. The \textit{servo-ctrl} will be able to adjust the servos 180$^\circ$ on an X and Y axis.


\subsubsection{voice-ctrl}

The \textit{voice-ctrl} is responsible for handling the microphone hardware. It will start and stop the voice recording and handle saving the sound recordings to hard disk. Ideally it will recognise gaps in audio patterns and save the data in "chunks" of speech for easier processing. 



\subsubsection{text-to-speech}

The \textit{text-to-speech} sub-process will monitor for new recording files and transmit them to the Internet for conversion. Once the audio recordings have been translated, it will concatenate the audio files together and add the running transcript.


\subsubsection{comm}

Both the \textit{client} and \textit{server} will communicate with each other via a message queue implemented over TCP or UDP. The communication will be managed by a \textit{comm} sub-process on both devices. Figure \ref{fig:comm} is a high level diagram of how the communication will occur.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{graphs/comm.pdf}
\caption{High level illustration of inter-device communication.}
\label{fig:comm}
\end{figure}


\section{Testing Issues}

There will be multiple hardware dependant components to be built for the project and limited hardware ownership within the group. The project can be built in parts, however they will need to be brought together to test everything works in unison.

\subsection{Types of Testing to be conducted}

We will need to regularly run hardware tests to ensure that we are using all the system resources efficiently.

We also need to run test on the audio quality being captured. We have already found that even with the direction microphone, interference can be caused from the hardware circuitry. 

Additional tests still being explored from our initial brainstorming session include:

\begin{enumerate}
  \item \textit{Power consumption:} a multimeter has been acquired to begin benchmarking power consumption of the \rpi\xspace at various stages of operation.
  \item \textit{Computer vision target tracking:} as a way to simulate field testing, the team is exploring using lecture theatre video captures (available through channels such as OpenCourseWare, YouTube, etc.) to identify any issues that may arise from environmental factors. For example, poor lighting conditions.

\end{enumerate}





\section{Roles and Responsibilities}

% Criterion 5 Team Roles  - Roles and responsibilities of each team member. A simple breakdown of primary and secondary tasks for each person.


Due to an unfortunate circumstance, our final group didn't form until week four. As a result there is cross-overs in our teams individual strengths. The roles have been divided with some shared responsibilities for delivering the final solution. Although at different levels, all three group members will be writing software, documenting and experimenting with hardware.


\subsection{Val Lyashov}
\textit{Val} has been working with computer components since he was 16. He will take on the role of designing the hardware solution and providing the operating environment. He will also be responsible for drafting some software interfaces to the hardware in Python, which will later be ported to C/C++ by the other members.


\subsection{"Alfred" Yang Yuan}
\textit{Alfred} is an experienced programmer who has professionally worked with C++ for over 3 years. He will be responsible for the final software architecture and optimisation of the software layer. His role will also involve improving the code written by the other team members to be multi-threaded and run efficiently with the hardware.

\subsection{Neil Ang}
\textit{Neil} has strong programming background and a particular interest in intelligent system design. He will be responsible for implementing the subject tracking and writing some C/C++ interfaces to the hardware. He will also take on the responsible for the technical writing and leadership of the group. 


\begin{appendices}
\chapter{Reflections of the Raspberry Pi Cross-Compiler build}

\subsection*{Did only one person build the image or did each member of the team do it?}

Each member individually completed the cross-compiler task, but only one member was chosen to demonstrate it in the laboratory.

\subsection*{If more than one did it, did team members do it independently or did they do it 
collaboratively?}

Every member completed it individually. The provided instructions were fairly straightforward so there was no need to work on it collaboratively.

\subsection*{Did they have any problems? If so how did they overcome them? What were 
the fixes?}

Since we followed the instructions precisely there were no issues with the cross-compile. However, the instructions for setting up the .inputrc resulted in two members unable to press the 'c' key on their keyboard.

An improved version of the .inputrc script for backwards searching was later found on Stack Overflow\footnote{http://stackoverflow.com/questions/1030182/how-do-i-change-bash-history-completion-to-complete-whats-already-on-the-line}:

\begin{lstlisting}[frame=single]
"\e[A":history-search-backward
"\e[B":history-search-forward
\end{lstlisting}

\subsection*{Do they understand what the recipe scripts did? Why was a cross compiler 
necessary?}

Val had prior knowledge of cross-compiling and understood the scripts the best. The cross-compiling was necessary to build an image that would be runnable on the \rpi\xspace hardware. 

\subsection*{Why did the script use uClib and not glibc? What are the trade-offs?}

No sure. We didn't spend much time investigating this.

\subsection*{Did using this recipe help you gain confidence in using the UNIX command 
line? What man page entries did you use? }

Each member already had a basic understanding of unix, so we were already confident with using the command line. We didn't find the need to look up any man pages to complete the task. 

\end{appendices}


\nocite{*}
\printbibliography[heading=bibintoc]


\end{document}