\documentclass[11pt,a4paper,titlepage]{report}


% Document settings

\title{OSP Portfolio \\ Team $\langle$sql injection$\rangle$}

\author{
  Neil Ang\\
  \texttt{s3251533}
  \and
  ``Alfred" Yang Yuan\\
  \texttt{s3363619}
  \and
  Val Lyashov\\
  \texttt{s3366222}
}

\date{Semester 2, 2013}


% Change section numbering
%\renewcommand\thesection{\Roman{section}}
%\renewcommand\thesubsection{\Alph{subsection}}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}


% Enable smart quotes
\usepackage [english]{babel}
\usepackage [autostyle]{csquotes}
\MakeOuterQuote{"}

% Alias pi name
\usepackage{xspace}
\newcommand{\rpi}{\textit{Raspberry Pi\textsuperscript{\textregistered}}}
\newcommand{\rpis}{\textit{Raspberry Pi\textsuperscript{\textregistered}s}}

% Side by side graphics
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% Switch to biblatex
\usepackage{biblatex}
\bibliography{computer-vision}
\bibliography{audio}
\bibliography{servo}

% Add the bib to the toc
\DefineBibliographyStrings{english}{
  bibliography = {Bibliography},
}

% Better table height
\usepackage{tabu}

% The appendix
\usepackage{appendix}

% Code highlighting
\usepackage{listings}
\lstset{basicstyle=\ttfamily}

% For marking what's left to do
\usepackage{color}


\begin{document}


\maketitle

\pagebreak
\tableofcontents
\thispagestyle{empty}
\pagebreak

\section{Introduction}

\textcolor{red}{Can we use same as before?}


\section{Goals and Objectives}
\section{Feedback and Self-Reflection}
\subsection{Self Assessment}
\subsection{Summary of Prototype Demonstration}
\subsection{Peer Review Summary}

\textcolor{red}{This is waiting on the lab instructor to give us back our peer-review sheets.}


\subsection{Self Reflection / Lessons Learned}

\textcolor{red}{Individual responses here...}


\subsection{Description of how each learning objective is addressed}
\section{Assumptions and Dependencies}
\section{General Constraints}
\section{Development Methodology}

\textcolor{red}{Reinforce how we met learning objective 1 here.}


\subsection{Programming languages}

\textcolor{red}{Python for prototyping, C/C++ for performance.}


\subsection{Development tools}
\subsection{Collaboration tools}

\textcolor{red}{Git/GitHub}


\section{Difficulties Encountered}
\section{Architecture}
\subsection{System Design including configuration}
\subsection{Data Design}
\subsection{Program Design}
\subsubsection{Software Design}

\subsubsection{Source code or patches for all original work.}


Source code for simulating face detection. \textcolor{red}{TODO: move this under testing heading?}

\begin{lstlisting}[frame=single]
#include <iostream>
#include <cstdlib>
#include <unistd.h>
#include <stdio.h>
#include <string.h>

#define NA_DEFAULT_WAIT 3
#define NA_MIN_TOLERANCE 2
#define NA_DEFAULT_TOLERANCE 5

#define MAX(X,Y) ((X) > (Y) ? (X) : (Y))

int rand_num()
{
    return (rand() % 200 + 1) - 100;
}

int rand_with_tolerance(int t, int l)
{
    setvbuf(stdout, NULL, _IONBF, 0);
    int i;
    do {
        i = rand_num();
    } while (i > l+t || i < l-t);
    return i;
}

int main(int argc, const char * argv[])
{
    int x = 0;
    int y = 0;

    int t = NA_DEFAULT_TOLERANCE;
    int s = NA_DEFAULT_WAIT;

    for (int i = 1; i < argc; i++) {
        int v = i+1 <= argc;
        if (strcmp(argv[i], "-t") == 0 && v) {
            t = std::stoi(argv[i+1]);
            t = MAX(t, NA_MIN_TOLERANCE);
        }
        else if (strcmp(argv[i], "-s") == 0 && v) {
            s = std::stoi(argv[i+1]);
            s = MAX(s, 0);
        }
        else if (strcmp(argv[i], "-h") == 0) {
            std::cout << "Usage: -t <tolerance>
             -s <seconds>" << std::endl;
            return EXIT_SUCCESS;
        }

    }

    while (true) {
        x = rand_with_tolerance(t, x);
        y = rand_with_tolerance(t, y);
        printf("%d,%d\n", x, y);
        sleep(s);
    }

    return EXIT_SUCCESS;
}
\end{lstlisting}



\section{Testing Issues}
\subsection{Testing Done}
\subsection{Performance Bounds}
\subsection{Performance Experiments}

\section{Roles and Responsibilities}

As outlined in our original project specification, there was overlap in our teams individual strengths so the roles were divided with some shared responsibilities. Although at different levels, we wanted all three group members to be involved with experimenting with the hardware, writing software and documenting. The cross-over in roles made the progress slightly slower, but allowed each of us to trial something new.

\subsection{Val Lyashov}

\textcolor{red}{Add table about hardware solution}

\subsection{"Alfred" Yang Yuan}

\textcolor{red}{Add table about software solution}

\subsection{Neil Ang}

\textcolor{red}{Add table about whatever is left}


\section{Breakdown of Work Done by Team Member}

Each team member kept a detailed log of their activities. Below is a summary of what they achieved each week.

\subsection{Val Lyashov}

\begin{description}

  \item[Week 2] \hfill \\
      Formed team with Neil and discussed ideas for the project.
  \item[Week 3] \hfill \\
      Voted for a team restructure.
  \item[Week 4] \hfill \\
      Acquired new team member.
  \item[Week 5] \hfill \\
      Demonstrated cross-compile milestone in lab.
  \item[Week 6] \hfill \\
      ...
  \item[Week 7] \hfill \\
      ...
  \item[Week 8] \hfill \\
      Took a trip to Bunnings with Neil to build the servo mount.
  \item[Week 9] \hfill \\
      ...
  \item[Week 10] \hfill \\
      Presented project to lab group (see appendix). Started work on final project portfolio submission.
  \item[Week 11] \hfill \\
      Worked on final project portfolio submission.
  \item[Week 12] \hfill \\
      Continued work on project portfolio submission.

\end{description}


\subsection{"Alfred" Yang Yuan}

\begin{description}

  \item[Week 4] \hfill \\
      Joined the team.
  \item[Week 5] \hfill \\
      Demonstrated cross-compile milestone in lab.
  \item[Week 6] \hfill \\
      ...
  \item[Week 7] \hfill \\
      ...
  \item[Week 8] \hfill \\
      ...
  \item[Week 9] \hfill \\
      ...
  \item[Week 10] \hfill \\
      Presented project to lab group (see appendix). Started work on final project portfolio submission.
  \item[Week 11] \hfill \\
      Worked on final project portfolio submission.
  \item[Week 12] \hfill \\
      Continued work on project portfolio submission.

\end{description}

\subsection{Neil Ang}
See appendix for daily log of tasks.
\begin{description}

  \item[Week 2] \hfill \\
      Formed team with Val and discussed ideas for the project. Purchased \rpi. Completed cross-compile milestone. Installed Arch linux on \rpi. Started research into computer vision libraries.
  \item[Week 3] \hfill \\
      Purchased a RPi camera board. Installed Raspbian on \rpi. Researched depth sensing on the device. Prototyped face detection code on MBP with OpenCV. Acquired a web camera and tested on the device. Voted for a team restructure.
  \item[Week 4] \hfill \\
      Acquired new team member. Continued experimenting with OpenCV to improve performance running on the device. Started work on project specification.
  \item[Week 5] \hfill \\
      Demonstrated cross-compile milestone in lab. Continued work on project specification. Wrote test program to simulate face detection for Val.
  \item[Week 6] \hfill \\
      Finished the project specification. Ported the PIR motion sensing Python code to C.
  \item[Week 7] \hfill \\
      Researched IPC techniques. Acquired the servos and started work on porting code to C++.
  \item[Week 8] \hfill \\
      Solved issues with servo powers. Finished work on C++ wrapper for servos. Got face detection based movement working. Took a trip to Bunnings with Val to build the servo mount.
  \item[Week 9] \hfill \\
      Debugged issues with the servo wrapper when running on the Pi. Wrote simple daemon for automatically starting the server/client code. Wrote presentation and speech for next milestone.
  \item[Week 10] \hfill \\
      Presented project to lab group (see appendix). Started work on final project portfolio submission.
  \item[Week 11] \hfill \\
      Worked on final project portfolio submission.
  \item[Week 12] \hfill \\
      Continued work on project portfolio submission.

\end{description}


\section{Summary and Conclusions}
\section{References}



\begin{appendices}

\chapter{Gantt Chart}

\includegraphics[width=\textwidth]{graphs/gantt-chart.pdf}


\chapter{Project Specification }

\textcolor{red}{Add project spec}

\chapter{Presentation speech (Milestone 3)}


Hi, we're team $\langle$sql injection$\rangle$. We are Alfred, Val and Neil.Because the raspberry pi is small and portable, we wanted to build something that would take advantage of this. We also liked the idea of building something that would respond to its surroundings. So we decided on an ambitious project to modernise the phonograph (commonly known as a dictaphone), but combining subject tracking with targeted audio recording equipment.

Here you can see Alfred, demoing the project. As he moves the left/right/up/down the Pi detects his new position and reorients the the shotgun microphone. This particular microphone is designed for targeted audio, and will record sound up to 3 metres while excluding background noise. The intended use of this product would be for recording lectures and tutorials, and producing podcasts. Our original design also included audio-to-text conversion, so we could generate transcripts, but the translation library we were using didn’t work well with Australian or Russian or Chinese accents... so... we dropped that part.

The first learning objective was about design, development and debugging a complex program on the Pi. With three group members with different backgrounds, we had different preferences for building the project. Our approach was to modularise the solution and allow multiple members work on the same thing but in different languages. For example, the servo code was quickly prototyped in python to ensure it functioned correctly. Once it was working, another group member re-wrote the python into C++ code. As most of you would have come up against, compiling on the Pi was slow. So a lot of early development was done on laptops then later tested on the device. There were a few circumstances where code would work on our machines and not the device, but that was due to the differing versions of g++ we were using and not a big issue to fix. A bonus of working this way, was that we had access to IDE debuggers and static analysers. While trying to improve the performance of our code, we ran the program through "Instruments", which detected where the code was the slowest and also picked up on a memory leak. Since our project was about interacting with the physical world (i.e detecting faces, moving motors, sensing motion). We had to run a lot of manual benchmarking. Basically we would tweak the degree of movement in servos, re-run the code and roughly evaluate if it was getting better or worse.Finally, all source code was checked into git, and hosted on GitHub. We heart GitHub. We used it for our source code, project specification and to record our development logs and bibliography.

Leaning objective 2 was about assessing trade-offs in hardware on a constrained system. To make things easier we put decided to split the workload over two Pis. One for face detection and movement, the other for audio recording and processing. For the subject tracking we looked at multiple solutions. We first thought about using depth sensing with something like a MS Kinect sensor, but found out that it was too resource intensive, so we were limited to 2D visual processing, and settled on face detection because of the suitability for the solution. We could also have done colour tracking or background masking.To perform real-time face detection you take a snapshot from the camera, convert it to grayscale, equalise the histogram, then use a trained classifier (in our case Haar-like features) to scan the image for face shapes at different scales, repeat.There is a C++ based open source library called OpenCV, which implements the classifier we wanted to use. It also supports GPU processing, but only NVIDIA GPUs (which the Pi doesn’t have). So to run it on the Pi we had to do the whole thing on CPU. This gave us the challenge of finding ways to optimise the CPU-based face detection so that it would run in real-time and actually detect faces. We took an iterative approach to this.So we started a basic face detection script and ran it. It used 100\% of the CPU and took about a 15 seconds to process each frame. We were using a 720p camera, so the first obvious step was to reduce the frame size so we were processing to less. At 320x240 we able to process a frame every 4-5 seconds and dropped CPU usage down to 70\%. We also added some limits on how it searched, by giving it a minimum face size, and set it to only perform a rough search for the biggest face. We got it at around 50\% CPU and 2-3 seconds per frame. Not bad.Alfred, then had some brilliant ideas on improve the performance further. Original script was creating a matrix of pixels that were copied into RAM and processed, he switched the code to use the pointers from the cameras instead of rebuilding the pixel matrix locally, and processed them on background threads. When the camera moves the frames that are still being processed are dropped, because the position has changed. Also, because of the way we predict the program would be used, we could reduce the pixels to process even further, by remembering the last face position and targeting just that area first. With all the additions we got the face detection and movement happening at an acceptable speed. There are some limitation to the implementation, such as moving too fast for the camera, or recording a profile shot - but we chalk this up to the constraints of using a raspberry pi. We ran the same scripts on a modern day MBP, and the accuracy and speed were at least 4 times better.A face is a complex shape, so we also thought about detecting just an eye or a nose. We ran some  tests, which improved the overall FPS, but the accuracy was a lot less. So full face detection was our best option. 

Also in attempting to improve the overall performance of project modules (eg face detection, real time recording). We investigated modification to process scheduling, however due to the bare bones nature of our system, there was no competition for CPU time.

Learning objective 4 was about team work. This project was particularly hard to work on as a team. Like other teams in this class would have come across, we faced with the obstacle of limited time for such an ambitious project. Two of our members work full-time, and the other studies full-time, so we had to do a lot of work at night in isolation. The obvious solution was to modularise the project into components, and have each member deliver each week. As can be seen in the table, we also tried to reduce dependencies on deliverables, so if one ran over time it wouldn’t impact the next weeks deliverables.But our biggest team issue with the amount of hardware we were using. Besides the Pis, we only had purchased one microphone, one motion sensor, one set of servos etc. So only one team member had physical access to a piece of hardware at a time. To overcome this obstacle, we came up with the idea of writing hardware simulation scripts. For example, we wrote a C++ program that would simulate face detection and output fake coordinates - This meant Val could fine tune the motor movement without having the physical camera or the face detection code complete.Another problem with the amount of hardware, was that when we did meet together, we needed to bring a lot of equipment. The photo on the slide doesn’t really do justice to what it was like to haul 3x laptops, 3x pis, a router, networking cables, servo cables, PIR sensor breadboards, plus tools etc.Finally, as a team we also wanted to do cross-skill development, which made things slower but increased our personal learning. Each members primary role was designed to make use of their best strengths. But we also included cross-overs in the task so we could each try something new. For example, although Val was our expert hardware guy, Neil (who had very limited hardware experience) got to write some of the C interfaces to the hardware, which is something he had never done before. We did similar things with all roles so that we each learned something new.

\end{appendices}

\nocite{*}
\printbibliography[heading=bibintoc]


\end{document}